{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUKX__a1UgGt"
      },
      "source": [
        "# Ejemplo de Inferencia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyNm0cFM-IOt"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "uilXHQVW-RTg"
      },
      "outputs": [],
      "source": [
        "! pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZxlBx8OXUgGu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import json\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kzf_37QPUgGu"
      },
      "source": [
        "## Ajustes Iniciales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LrsYEZXHUgGv"
      },
      "outputs": [],
      "source": [
        "# Nombre del alumno\n",
        "student_name = \"leandro_salvañá\"\n",
        "\n",
        "# Ruta al archivo de pesos\n",
        "model_path = \"./Results/yolov8_retraining/weights/best.pt\"\n",
        "\n",
        "# Ruta al directorio que contiene las imagenes\n",
        "imgs_dir = \"./Data/eval/images/val\"\n",
        "\n",
        "# Ruta al directorio de destino de las detecciones\n",
        "base_dir = \"./Results/Envido\"\n",
        "dets_dir = os.path.join(base_dir, student_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XPb1-p0LUgGv"
      },
      "outputs": [],
      "source": [
        "# Reestablecimiento del directorio de destino (eliminacion)\n",
        "if os.path.exists(dets_dir):\n",
        "    shutil.rmtree(dets_dir)\n",
        "\n",
        "os.makedirs(dets_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlWUupvnUgGv"
      },
      "source": [
        "## Inferencia\n",
        "\n",
        "### Formato YOLOv5 para las salidas de las inferencias\n",
        "\n",
        "Estas son las celdas para que el estudiante complete con su código de inferencia.\n",
        "\n",
        "Debe generar un archivo con las detecciones en formato YOLOv5, donde cada línea contiene:\n",
        " cls, xc, yx, w, h, c\n",
        "\n",
        "* **cls**: número de índice de la clase\n",
        "\n",
        "* **xc**: coordenada x al centro de la caja delimitadora (bbox)\n",
        "\n",
        "* **yx**: coordenada y al centro de la caja delimitadora (bbox)\n",
        "\n",
        "* **w**: ancho de la caja delimitadora\n",
        "\n",
        "* **h**: alto de la caja delimitadora\n",
        "\n",
        "* **c**: certeza del modelo sobre la clasificacíon (confidence)\n",
        "\n",
        "\n",
        " Todas las coordenadas deben ser relativas: [0 ... 1]\n",
        "\n",
        "NOTA: Si utiliza un modelo YoloV8 de ultralytics, pueder llamar al método result.save_txt(file_name, save_conf=True)\n",
        "\n",
        "### Formato para los archivos de envido.json\n",
        "\n",
        "Además de las detecciones anteriores, debe existir un archivo llamado envido.json con la siguiente estructura:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"IMG_20240630_174514649_HDR.jpg\": {\n",
        "        \"total_cards\": 3,\n",
        "        \"cards\": {\n",
        "            \"E\": [],\n",
        "            \"C\": [\n",
        "                12\n",
        "            ],\n",
        "            \"B\": [\n",
        "                11\n",
        "            ],\n",
        "            \"O\": [\n",
        "                10\n",
        "            ]\n",
        "        },\n",
        "        \"points\": 0,\n",
        "        \"figure\": \"N/A\"\n",
        "    },\n",
        "    \"IMG_20240630_173918579.jpg\": {\n",
        "        \"total_cards\": 2,\n",
        "        \"cards\": {\n",
        "            \"E\": [],\n",
        "            \"C\": [],\n",
        "            \"B\": [],\n",
        "            \"O\": [\n",
        "                9,\n",
        "                8\n",
        "            ]\n",
        "        },\n",
        "        \"points\": 0,\n",
        "        \"figure\": \"N/A\"\n",
        "    },\n",
        "  ...\n",
        "}\n",
        "```\n",
        "\n",
        "Esto indica que hay un total de tres cartas, que son el 5 y el 1 de Copas, y el 2 de Basto, que dan 26 puntos de envido de Copa.\n",
        "\n",
        "Este archivo debe contener una clave con el nombre de archivo, donde cada elemento es a su vez un objeto cons las claves detalladas.\n",
        "\n",
        "Revise el archivo gt_envido.json para analizar todas las posibilidades."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEvz0ZGdUgGw"
      },
      "source": [
        "### DEMO: cálculo del envido\n",
        "\n",
        "A continuación hay una implementación del cálculo de los puntos a modo de ejemplo, que sirve de referencia para evaluar el algoritmo de evaluación.\n",
        "\n",
        "**ESTA ES LA SECCIÓN QUE CADA ALUMNO REEMPLAZARIA CON SU CODIGO**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "prcIq_tjUgGw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_173929084.jpg: 640x512 1 3O, 1 5O, 1 6O, 1 7O, 195.7ms\n",
            "Speed: 12.3ms preprocess, 195.7ms inference, 10.0ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_173836085.jpg: 640x512 1 6B, 1 7E, 112.8ms\n",
            "Speed: 3.9ms preprocess, 112.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_173828513_HDR.jpg: 640x512 1 3B, 1 6B, 1 7E, 162.1ms\n",
            "Speed: 5.6ms preprocess, 162.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_174434126.jpg: 640x512 1 7C, 1 12O, 159.5ms\n",
            "Speed: 6.0ms preprocess, 159.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_173918579.jpg: 640x512 1 7O, 1 8O, 132.2ms\n",
            "Speed: 3.0ms preprocess, 132.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_174142929_HDR.jpg: 640x512 1 3E, 101.0ms\n",
            "Speed: 2.7ms preprocess, 101.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_174005265.jpg: 640x512 1 1O, 69.1ms\n",
            "Speed: 3.0ms preprocess, 69.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_174208092.jpg: 640x512 1 5E, 1 11O, 1 12O, 71.4ms\n",
            "Speed: 2.8ms preprocess, 71.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_174017809.jpg: 640x512 1 7E, 1 9B, 71.2ms\n",
            "Speed: 3.5ms preprocess, 71.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_173758691.jpg: 640x512 1 1C, 1 2B, 103.3ms\n",
            "Speed: 4.5ms preprocess, 103.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_173711753_HDR.jpg: 640x512 1 11C, 104.0ms\n",
            "Speed: 6.3ms preprocess, 104.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_174155383_HDR.jpg: 640x512 2 12Es, 110.2ms\n",
            "Speed: 4.4ms preprocess, 110.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_174316833.jpg: 640x512 (no detections), 102.5ms\n",
            "Speed: 3.8ms preprocess, 102.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_174453153.jpg: 640x512 1 1B, 1 3C, 95.8ms\n",
            "Speed: 2.9ms preprocess, 95.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_174133804_HDR.jpg: 640x512 1 3E, 1 4E, 1 5E, 85.7ms\n",
            "Speed: 2.9ms preprocess, 85.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_173822184_HDR.jpg: 640x512 1 7E, 1 9B, 89.4ms\n",
            "Speed: 3.0ms preprocess, 89.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_174223161_HDR.jpg: 640x512 1 9O, 1 12B, 71.3ms\n",
            "Speed: 4.2ms preprocess, 71.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_174418639.jpg: 640x512 1 6O, 1 10O, 81.8ms\n",
            "Speed: 3.0ms preprocess, 81.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_173954348.jpg: 640x512 (no detections), 73.7ms\n",
            "Speed: 2.8ms preprocess, 73.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_174105714.jpg: 640x512 1 8B, 87.3ms\n",
            "Speed: 2.8ms preprocess, 87.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_173737533.jpg: 640x512 1 1C, 1 2B, 1 5C, 106.7ms\n",
            "Speed: 3.4ms preprocess, 106.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_174302382_HDR.jpg: 640x512 1 1E, 1 6C, 66.6ms\n",
            "Speed: 3.0ms preprocess, 66.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_174459285.jpg: 512x640 1 5B, 89.5ms\n",
            "Speed: 4.7ms preprocess, 89.5ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_174406256.jpg: 640x512 1 5O, 1 6O, 1 7O, 1 10O, 1 10C, 66.4ms\n",
            "Speed: 2.7ms preprocess, 66.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_174349395.jpg: 640x512 1 7O, 1 10B, 1 11B, 67.3ms\n",
            "Speed: 3.0ms preprocess, 67.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_174115784.jpg: 640x512 1 8C, 1 9E, 88.2ms\n",
            "Speed: 3.2ms preprocess, 88.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_174333447.jpg: 640x512 1 1B, 1 7B, 89.3ms\n",
            "Speed: 3.8ms preprocess, 89.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_174246178_HDR.jpg: 640x512 1 2C, 93.8ms\n",
            "Speed: 3.4ms preprocess, 93.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_174445046_HDR.jpg: 640x512 (no detections), 74.3ms\n",
            "Speed: 3.1ms preprocess, 74.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_173859456.jpg: 640x512 1 3B, 61.9ms\n",
            "Speed: 3.0ms preprocess, 61.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_174235296.jpg: 640x512 1 4O, 1 8C, 1 10E, 72.7ms\n",
            "Speed: 2.9ms preprocess, 72.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "image 1/1 /home/salvanya/TP-CV2/Data/eval/images/val/IMG_20240630_174514649_HDR.jpg: 640x512 3 11Bs, 1 12O, 1 12C, 112.8ms\n",
            "Speed: 3.0ms preprocess, 112.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
            "Inferencia completada. Resultados guardados en ./Results/Envido/leandro_salvañá.\n"
          ]
        }
      ],
      "source": [
        "# Cargar el modelo entrenado\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Realizar inferencia sobre todas las imágenes del directorio\n",
        "image_files = [f for f in os.listdir(imgs_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "for image_file in image_files:\n",
        "    # Obtener el nombre base\n",
        "    base_name = image_file[:image_file.rfind('.')]\n",
        "   \n",
        "    # Crear el nombre para el txt\n",
        "    txt_name = base_name + '.txt'\n",
        "    \n",
        "    # Ruta del txt\n",
        "    txt_path = os.path.join(dets_dir, txt_name)\n",
        "    \n",
        "    # Ruta de la imagen\n",
        "    image_path = os.path.join(imgs_dir, image_file)\n",
        "\n",
        "    # Realizar inferencia\n",
        "    result = model(image_path)\n",
        "    \n",
        "    # Guardar los resultados en el directorio de detecciones\n",
        "    result[0].save_txt(txt_path , save_conf=True)\n",
        "\n",
        "print(f\"Inferencia completada. Resultados guardados en {dets_dir}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'IMG_20240630_173929084.jpg': ['7O', '3O', '6O', '5O'], 'IMG_20240630_174418639.jpg': ['6O', '10O'], 'IMG_20240630_174223161_HDR.jpg': ['9O', '12B'], 'IMG_20240630_174246178_HDR.jpg': ['2C'], 'IMG_20240630_174235296.jpg': ['4O', '8C', '10E'], 'IMG_20240630_173822184_HDR.jpg': ['9B', '7E'], 'IMG_20240630_174434126.jpg': ['7C', '12O'], 'IMG_20240630_174133804_HDR.jpg': ['4E', '5E', '3E'], 'IMG_20240630_173918579.jpg': ['7O', '8O'], 'IMG_20240630_174155383_HDR.jpg': ['12E'], 'IMG_20240630_174115784.jpg': ['8C', '9E'], 'IMG_20240630_174453153.jpg': ['3C', '1B'], 'IMG_20240630_173758691.jpg': ['1C', '2B'], 'IMG_20240630_174514649_HDR.jpg': ['12C', '11B', '12O'], 'IMG_20240630_174333447.jpg': ['7B', '1B'], 'IMG_20240630_174349395.jpg': ['10B', '11B', '7O'], 'IMG_20240630_173828513_HDR.jpg': ['3B', '6B', '7E'], 'IMG_20240630_174302382_HDR.jpg': ['6C', '1E'], 'IMG_20240630_174005265.jpg': ['1O'], 'IMG_20240630_173711753_HDR.jpg': ['11C'], 'IMG_20240630_173859456.jpg': ['3B'], 'IMG_20240630_174142929_HDR.jpg': ['3E'], 'IMG_20240630_173836085.jpg': ['7E', '6B'], 'IMG_20240630_174017809.jpg': ['9B', '7E'], 'IMG_20240630_174459285.jpg': ['5B'], 'IMG_20240630_174105714.jpg': ['8B'], 'IMG_20240630_173737533.jpg': ['5C', '1C', '2B'], 'IMG_20240630_174208092.jpg': ['11O', '5E', '12O'], 'IMG_20240630_174406256.jpg': ['10O', '5O', '7O', '6O', '10C']}\n"
          ]
        }
      ],
      "source": [
        "# Lista de clases\n",
        "classes = [\n",
        "    '1O', '1C', '1E', '1B', '2O', '2C', '2E', '2B', '3O', '3C', '3E', '3B', \n",
        "    '4O', '4C', '4E', '4B', '5O', '5C', '5E', '5B', '6O', '6C', '6E', '6B', \n",
        "    '7O', '7C', '7E', '7B', '8O', '8C', '8E', '8B', '9O', '9C', '9E', '9B', \n",
        "    '10O', '10C', '10E', '10B', '11O', '11C', '11E', '11B', '12O', '12C', \n",
        "    '12E', '12B', 'J'\n",
        "]\n",
        "\n",
        "# Obtener lista de imágenes con extensiones válidas\n",
        "valid_extensions = ['.png', '.jpg', '.jpeg']\n",
        "image_files = [f for f in os.listdir(imgs_dir) if os.path.splitext(f)[1].lower() in valid_extensions]\n",
        "\n",
        "# Crear diccionario de imagen base y su extensión\n",
        "image_dict = {os.path.splitext(f)[0]: f for f in image_files}\n",
        "\n",
        "# Inicializar diccionario de resultados\n",
        "results_dict = {}\n",
        "\n",
        "# Leer archivos .txt en dets_dir\n",
        "txt_files = [f for f in os.listdir(dets_dir) if f.endswith('.txt')]\n",
        "\n",
        "for txt_file in txt_files:\n",
        "    base_name = os.path.splitext(txt_file)[0]\n",
        "    \n",
        "    # Verificar si la imagen correspondiente existe\n",
        "    if base_name in image_dict:\n",
        "        image_name = image_dict[base_name]\n",
        "        image_classes = []\n",
        "        \n",
        "        # Leer el archivo .txt y obtener las clases\n",
        "        txt_path = os.path.join(dets_dir, txt_file)\n",
        "        with open(txt_path, 'r') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                class_id = int(parts[0])\n",
        "                class_name = classes[class_id]\n",
        "                image_classes.append(class_name)\n",
        "        \n",
        "        # Añadir al diccionario de resultados\n",
        "        results_dict[image_name] = image_classes\n",
        "\n",
        "# Eliminar detecciones múltiples\n",
        "for image_name, classes in results_dict.items():\n",
        "    results_dict[image_name] = list(set(classes))\n",
        "\n",
        "print(results_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'IMG_20240630_173929084.jpg': {'total_cards': 4, 'cards': {'E': [], 'C': [], 'B': [], 'O': [7, 3, 6, 5]}, 'points': 33, 'figure': 'O'}, 'IMG_20240630_174418639.jpg': {'total_cards': 2, 'cards': {'E': [], 'C': [], 'B': [], 'O': [6, 10]}, 'points': 0, 'figure': 'N/A'}, 'IMG_20240630_174223161_HDR.jpg': {'total_cards': 2, 'cards': {'E': [], 'C': [], 'B': [12], 'O': [9]}, 'points': 0, 'figure': 'N/A'}, 'IMG_20240630_174246178_HDR.jpg': {'total_cards': 1, 'cards': {'E': [], 'C': [2], 'B': [], 'O': []}, 'points': 2, 'figure': 'C'}, 'IMG_20240630_174235296.jpg': {'total_cards': 3, 'cards': {'E': [10], 'C': [8], 'B': [], 'O': [4]}, 'points': 4, 'figure': 'O'}, 'IMG_20240630_173822184_HDR.jpg': {'total_cards': 2, 'cards': {'E': [7], 'C': [], 'B': [9], 'O': []}, 'points': 7, 'figure': 'E'}, 'IMG_20240630_174434126.jpg': {'total_cards': 2, 'cards': {'E': [], 'C': [7], 'B': [], 'O': [12]}, 'points': 7, 'figure': 'C'}, 'IMG_20240630_174133804_HDR.jpg': {'total_cards': 3, 'cards': {'E': [4, 5, 3], 'C': [], 'B': [], 'O': []}, 'points': 29, 'figure': 'E'}, 'IMG_20240630_173918579.jpg': {'total_cards': 2, 'cards': {'E': [], 'C': [], 'B': [], 'O': [7, 8]}, 'points': 0, 'figure': 'N/A'}, 'IMG_20240630_174155383_HDR.jpg': {'total_cards': 1, 'cards': {'E': [12], 'C': [], 'B': [], 'O': []}, 'points': 0, 'figure': 'N/A'}, 'IMG_20240630_174115784.jpg': {'total_cards': 2, 'cards': {'E': [9], 'C': [8], 'B': [], 'O': []}, 'points': 0, 'figure': 'N/A'}, 'IMG_20240630_174453153.jpg': {'total_cards': 2, 'cards': {'E': [], 'C': [3], 'B': [1], 'O': []}, 'points': 3, 'figure': 'C'}, 'IMG_20240630_173758691.jpg': {'total_cards': 2, 'cards': {'E': [], 'C': [1], 'B': [2], 'O': []}, 'points': 2, 'figure': 'B'}, 'IMG_20240630_174514649_HDR.jpg': {'total_cards': 3, 'cards': {'E': [], 'C': [12], 'B': [11], 'O': [12]}, 'points': 0, 'figure': 'N/A'}, 'IMG_20240630_174333447.jpg': {'total_cards': 2, 'cards': {'E': [], 'C': [], 'B': [7, 1], 'O': []}, 'points': 28, 'figure': 'B'}, 'IMG_20240630_174349395.jpg': {'total_cards': 3, 'cards': {'E': [], 'C': [], 'B': [10, 11], 'O': [7]}, 'points': 7, 'figure': 'O'}, 'IMG_20240630_173828513_HDR.jpg': {'total_cards': 3, 'cards': {'E': [7], 'C': [], 'B': [3, 6], 'O': []}, 'points': 29, 'figure': 'B'}, 'IMG_20240630_174302382_HDR.jpg': {'total_cards': 2, 'cards': {'E': [1], 'C': [6], 'B': [], 'O': []}, 'points': 6, 'figure': 'C'}, 'IMG_20240630_174005265.jpg': {'total_cards': 1, 'cards': {'E': [], 'C': [], 'B': [], 'O': [1]}, 'points': 1, 'figure': 'O'}, 'IMG_20240630_173711753_HDR.jpg': {'total_cards': 1, 'cards': {'E': [], 'C': [11], 'B': [], 'O': []}, 'points': 0, 'figure': 'N/A'}, 'IMG_20240630_173859456.jpg': {'total_cards': 1, 'cards': {'E': [], 'C': [], 'B': [3], 'O': []}, 'points': 3, 'figure': 'B'}, 'IMG_20240630_174142929_HDR.jpg': {'total_cards': 1, 'cards': {'E': [3], 'C': [], 'B': [], 'O': []}, 'points': 3, 'figure': 'E'}, 'IMG_20240630_173836085.jpg': {'total_cards': 2, 'cards': {'E': [7], 'C': [], 'B': [6], 'O': []}, 'points': 7, 'figure': 'E'}, 'IMG_20240630_174017809.jpg': {'total_cards': 2, 'cards': {'E': [7], 'C': [], 'B': [9], 'O': []}, 'points': 7, 'figure': 'E'}, 'IMG_20240630_174459285.jpg': {'total_cards': 1, 'cards': {'E': [], 'C': [], 'B': [5], 'O': []}, 'points': 5, 'figure': 'B'}, 'IMG_20240630_174105714.jpg': {'total_cards': 1, 'cards': {'E': [], 'C': [], 'B': [8], 'O': []}, 'points': 0, 'figure': 'N/A'}, 'IMG_20240630_173737533.jpg': {'total_cards': 3, 'cards': {'E': [], 'C': [5, 1], 'B': [2], 'O': []}, 'points': 26, 'figure': 'C'}, 'IMG_20240630_174208092.jpg': {'total_cards': 3, 'cards': {'E': [5], 'C': [], 'B': [], 'O': [11, 12]}, 'points': 5, 'figure': 'E'}, 'IMG_20240630_174406256.jpg': {'total_cards': 5, 'cards': {'E': [], 'C': [10], 'B': [], 'O': [10, 5, 7, 6]}, 'points': 33, 'figure': 'O'}}\n"
          ]
        }
      ],
      "source": [
        "# Puntajes de las cartas\n",
        "points_dict = {\n",
        "    1: 1,\n",
        "    2: 2,\n",
        "    3: 3,\n",
        "    4: 4,\n",
        "    5: 5,\n",
        "    6: 6,\n",
        "    7: 7,\n",
        "    8: 0,\n",
        "    9: 0,\n",
        "    10: 0,\n",
        "    11: 0,\n",
        "    12: 0\n",
        "}\n",
        "\n",
        "# Función para calcular puntos y palo\n",
        "def calculate_points_and_figure(cards_dict):\n",
        "    counts = {key: len(cards_dict[key]) for key in cards_dict}\n",
        "    max_point = 0\n",
        "    max_figure = \"N/A\"\n",
        "    \n",
        "    # Filtrar clases con más de una carta y sumar puntos\n",
        "    for key, values in cards_dict.items():\n",
        "        if len(values) > 0:\n",
        "            # Obtener máximo puntaje y figura\n",
        "            max_card = max(values)\n",
        "            if points_dict[max_card] > max_point:\n",
        "                max_point = points_dict[max_card]\n",
        "                max_figure = key\n",
        "            \n",
        "            # Sumar puntos de cartas válidas (no 8 o 9)\n",
        "            valid_points = [points_dict[card] for card in values if points_dict[card] > 0]\n",
        "            if len(valid_points) > 1:\n",
        "                max_point = max(max_point, sum(sorted(valid_points)[-2:]) + 20)\n",
        "                max_figure = key\n",
        "    \n",
        "    return max_point, max_figure\n",
        "\n",
        "# Construir el nuevo diccionario\n",
        "card_ds_file = {}\n",
        "\n",
        "for image_name, classes in results_dict.items():\n",
        "    # Inicializar estructura\n",
        "    card_entry = {\n",
        "        \"total_cards\": len(classes),\n",
        "        \"cards\": {\n",
        "            \"E\": [],\n",
        "            \"C\": [],\n",
        "            \"B\": [],\n",
        "            \"O\": []\n",
        "        },\n",
        "        \"points\": 0,\n",
        "        \"figure\": \"N/A\"\n",
        "    }\n",
        "    \n",
        "    # Descomponer las clases en el diccionario de cartas\n",
        "    for class_label in classes:\n",
        "        number = int(class_label[:-1])\n",
        "        letter = class_label[-1]\n",
        "        card_entry[\"cards\"][letter].append(number)\n",
        "    \n",
        "    # Calcular puntos y figura\n",
        "    points, figure = calculate_points_and_figure(card_entry[\"cards\"])\n",
        "    card_entry[\"points\"] = points\n",
        "    card_entry[\"figure\"] = figure\n",
        "    \n",
        "    # Añadir entrada al diccionario final\n",
        "    card_ds_file[image_name] = card_entry\n",
        "\n",
        "print(card_ds_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3K0mr20UgGx"
      },
      "source": [
        "## Escritura del archivo envido.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Y-98aHWTUgGx"
      },
      "outputs": [],
      "source": [
        "with open(os.path.join(dets_dir, \"envido.json\"), \"w\") as jf:\n",
        "    json.dump(card_ds_file, jf, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Escritura de archivo gt_envido.json \n",
        "\n",
        "Esta celda responde a una confusión con el README.txt. Porque la celda anterior, que ya venía escrita, hace que el JSON se guarde en dets_dir, es decir, el directorio que definimos al principio. Pero en el README.txt dice que en el archivo \"gt_envido.json\" tiene que estar en la misma carpeta que el dataset.yaml, que a su vez tiene que tener dos directorios uno con las imágenes y otra con las etiquetas. No sé si ese JSON el que ya viene con el código de evaluación provisto o el que tengo que crear yo. Porque el código que vino escrito en la celda anterior, escribe un archivo \"envido.json\" no un \"gt_envido.json\", y además lo hace en un directorio, a priori, independiente.\n",
        "\n",
        "Entonces, de ser incorrecta la escritura del json anterior, descomentar y correr la siguiente celda para que el json que se escriba lleve el nombre \"gt_envido.json\" y esté en el mismo directorio que el yaml."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# with open(os.path.join('data/eval', \"gt_envido.json\"), \"w\") as jf:\n",
        "#     json.dump(card_ds_file, jf, indent=4)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
